
<!DOCTYPE html>
<html lang class="loading">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Target Detection - Dong</title>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate">
    <meta name="keywords" content="Dongdong,"> 
    <meta name="description" content="Target Detection
This blog contains some useful information for Brand Detection project, which incl,"> 
    <meta name="author" content="John Doe"> 
    <link rel="alternative" href="atom.xml" title="Dong" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link rel="stylesheet" href="/css/diaspora.css">
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads" src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
</head>
</html>
<body class="loading">
    <span id="config-title" style="display:none">Dong</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="icon-home image-icon" href="javascript:;" data-url="http://yoursite.com"></a>
    <div title="播放/暂停" class="icon-play"></div>
    <h3 class="subtitle">Target Detection</h3>
    <div class="social">
        <!--<div class="like-icon">-->
            <!--<a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
        <!--</div>-->
        <div>
            <div class="share">
                <a title="获取二维码" class="icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">Target Detection</h1>
        <div class="stuff">
            <span>七月 01, 2019</span>
            

        </div>
        <div class="content markdown">
            <h1 id="Target-Detection"><a href="#Target-Detection" class="headerlink" title="Target Detection"></a>Target Detection</h1><hr>
<p>This blog contains some useful information for Brand Detection project, which includes basic information about CNN, introduction of target detection problem, some papers and alg about TDP.</p>
<h2 id="labelImg"><a href="#labelImg" class="headerlink" title="labelImg"></a>labelImg</h2><hr>
<p>Reference:</p>
<ul>
<li><p><a href="https://github.com/tzutalin/labelImg#labelimg" target="_blank" rel="noopener">labelImg</a></p>
</li>
<li><p><a href="https://www.youtube.com/watch?v=nw1GexJzbCI&feature=youtu.be" target="_blank" rel="noopener">A demo video</a></p>
</li>
</ul>
<p>LabelImg is a graphical image annotation tool.</p>
<p>It is written in Python and uses Qt for its graphical interface.</p>
<p>Annotations are saved as XML files in PASCAL VOC format, the format used by ImageNet. Besides, it also supports YOLO format.</p>
<p>Install labelImg:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install labelImg</span><br><span class="line"><span class="comment">## Run the software</span></span><br><span class="line">labelImg</span><br></pre></td></tr></table></figure>

<p>We label the image by labelImg which will return a .xml file contains the label information and the size of label box.</p>
<p><img src="/images/labelImg.jpg" alt="CNN"></p>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><hr>
<p>Reference:</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/33855959" target="_blank" rel="noopener">CNN 入门讲解专栏阅读顺序以及论文研读视频集合</a></li>
</ul>
<p>Usually we have 3 different layers inside our cnn model. They are:</p>
<ul>
<li><p>Convolution layer</p>
<p>  Extracting features.</p>
</li>
<li><p>Pooling layer</p>
<p>  Choosing features.</p>
</li>
<li><p>Full connect layer.</p>
<p>  prediction.</p>
</li>
</ul>
<p><img src="/images/cnn.jpg" alt="CNN"></p>
<h3 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h3><hr>
<h2 id="Target-Detection-Problem-TDP"><a href="#Target-Detection-Problem-TDP" class="headerlink" title="Target Detection Problem(TDP)"></a>Target Detection Problem(TDP)</h2><hr>
<p>Reference:</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/34142321" target="_blank" rel="noopener">干货 | 目标检测入门，看这篇就够了</a></p>
</li>
<li><p><a href="https://www.davex.pw/2018/02/09/overview-of-object-detection/" target="_blank" rel="noopener">基于深度学习的「目标检测」算法综述</a></p>
</li>
</ul>
<p>What is TDP?</p>
<p>The input is a full image. However, dection only care about the specific items. And, we need to get the position and classification information at the sametime. The output is a list which contains the positions and classes.</p>
<p>We have two kinds of dection algorithm.</p>
<ol>
<li><p>2-stage Algorithm:</p>
<ul>
<li><p>Get Region Proposal and get features by CNN.</p>
</li>
<li><p>Classify by classification function(usually SVM).</p>
<p>for examples:</p>
</li>
<li><p>R-CNN -&gt; SPP Net -&gt; Fast R-CNN -&gt; <strong>Faster R-CNN</strong> -&gt; Mask R-CNN</p>
</li>
</ul>
</li>
<li><p>1-stage algorithm:</p>
<p> TOLO and SSD.</p>
</li>
</ol>
<p>Comparing:</p>
<ul>
<li><p>speed: 1-stage &gt; 2-stage</p>
</li>
<li><p>accuracy: 2-stage &gt; 1-stage</p>
</li>
</ul>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><hr>
<p>Reference:</p>
<ul>
<li><p>Paper: <a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank" rel="noopener">Rich feature hierarchies for accurate object detection and semantic segmentation</a></p>
</li>
<li><p>Blog: <a href="https://www.davex.pw/2018/02/10/paper-reading-of-rcnn/" target="_blank" rel="noopener">目标检测：R-CNN 论文阅读</a></p>
</li>
</ul>
<p><img src="/images/rcnn.png" alt="CNN"></p>
<p>Four main steps in R-CNN:</p>
<ol>
<li><p>Use selective search alg to do the Region Proposal.</p>
</li>
<li><p>CNN feature extraction.</p>
</li>
<li><p>Training SVM to classify regions.</p>
</li>
<li><p>Bounding Box Refine.</p>
</li>
</ol>
<h4 id="Region-Proposal"><a href="#Region-Proposal" class="headerlink" title="Region Proposal."></a>Region Proposal.</h4><hr>
<p>Intersection over Union(IoU)</p>
<h4 id="CNN-model"><a href="#CNN-model" class="headerlink" title="CNN model"></a>CNN model</h4><hr>
<p>Reference: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional<br>Neural Networks</a></p>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><hr>
<p>Reference:</p>
<ul>
<li>Paper: <a href="https://arxiv.org/pdf/1504.08083.pdf" target="_blank" rel="noopener">Fast Region-based Convolutional Network, R. Girshick 2015</a></li>
</ul>
<h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><hr>
<p>Reference:</p>
<ul>
<li>Paper: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN: Towards Real Time Object Detection with Region Proposal Networks</a></li>
</ul>
<h4 id="Tensorflow-Object-Detection-API"><a href="#Tensorflow-Object-Detection-API" class="headerlink" title="Tensorflow Object Detection API"></a>Tensorflow Object Detection API</h4><hr>
<p>Discription writen by Google:</p>
<p>Creating accurate machine learning models capable of localizing and identifying multiple objects in a single image remains a core challenge in computer vision. The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models. At Google we’ve certainly found this codebase to be useful for our computer vision needs, and we hope that you will as well.</p>
<ul>
<li><p>Model: <a href="https://github.com/tensorflow/models/tree/master/research/object_detection" target="_blank" rel="noopener">Object_detection</a></p>
</li>
<li><p>How to use this model:</p>
<p>  Following are some tutorials about how to use this model.</p>
<ul>
<li><p><a href="https://towardsdatascience.com/is-google-tensorflow-object-detection-api-the-easiest-way-to-implement-image-recognition-a8bd1f500ea0" target="_blank" rel="noopener">get a start with the model</a></p>
<p>  Get a quick start. Run the test image with pre-trained model.</p>
</li>
<li><p><a href="https://towardsdatascience.com/building-a-toy-detector-with-tensorflow-object-detection-api-63c0fdf2ac95" target="_blank" rel="noopener">Second step</a></p>
<p>  Get the model yourself. Training the model with your own dataset.</p>
</li>
<li><p><a href="https://towardsdatascience.com/using-object-detection-for-a-smarter-retail-checkout-experience-3f39acef857b" target="_blank" rel="noopener">final</a></p>
<p>  Build a model which can fix a more complex problem. For example, videos and conbain two different model together.</p>
</li>
</ul>
</li>
<li><p>How to set the environment to get a start:</p>
<p>  download tensorflow:</p>
<pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow</span><br><span class="line"><span class="comment">## tensorflow gpu</span></span><br><span class="line">pip install tensorflow-gpu</span><br></pre></td></tr></table></figure></code></pre><p>  If you are using conda, highly recommend build your onw environment. Please follow the following steps.</p>
<p>  step 1: set a environment for tensorflow</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#create a env for tensorflow</span></span><br><span class="line">conda create -n tensorflow python=3.6</span><br><span class="line"></span><br><span class="line"><span class="comment">#actovate the environment</span></span><br><span class="line">activate tensorflow</span><br></pre></td></tr></table></figure>

<p>  step 2: install anaconda</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canda install anaconda</span><br></pre></td></tr></table></figure>

<p>  step 3: install tensorflow</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">canda install anaconda</span><br><span class="line"><span class="comment">#tensorflow-gpu</span></span><br><span class="line">canda install anaconda-gpu</span><br></pre></td></tr></table></figure>

<p>  step 4: Maybe you need to undate you conda tenforflow</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#check the version of conda tensorflow</span></span><br><span class="line">anaconda search -t conda tensorflow</span><br><span class="line"></span><br><span class="line"><span class="comment">#find the version you want and match youe environment</span></span><br><span class="line">anaconda show &lt;USER/PACKAGE&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#according to the donwload url from upper step, downloard tensorflow</span></span><br><span class="line"></span><br><span class="line">conda install --channel https://conda.anaconda.org/anaconda tensorflow</span><br></pre></td></tr></table></figure>

<p>  setp 5: Set up you jupyter environment. Now you have your tensorflow env in your.</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m ipykernel install --user --name env_name --display-name <span class="string">"Python env"</span></span><br></pre></td></tr></table></figure></li>
</ul>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        <li title='0' data-url='http://link.hhtjim.com/163/5146554.mp3'></li>
                    
                        <li title='1' data-url='http://link.hhtjim.com/qq/001faIUs4M2zna.mp3'></li>
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>
<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>




</html>
